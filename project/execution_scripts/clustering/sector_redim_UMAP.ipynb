{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 自作モジュール\n",
        "from utils.paths import Paths\n",
        "from acquisition.jquants_api_operations import StockAcquisitionFacade\n",
        "from utils.jquants_api_utils import cli\n",
        "from calculation.target import TargetCalculator\n",
        "# 基本モジュール\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# クラスタリングで使用\n",
        "from clustering import UMAPReducer, HDBSCANCluster, EuclideanClusterAssigner, SectorClusterer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 銘柄情報の取得\n",
        "* stock_lists: 2014年10月からの銘柄一覧\n",
        "* history_list: 銘柄ごとのScaleCategoryの遍歴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1295,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_codes = [\"4912\",\"4917\",\"7956\",\"8113\",\"4919\",\"4928\",\"6630\",\"7744\",\"4452\",\"4967\",\"8283\",\"4028\",\"4911\",\"4922\",\"4927\"]\n",
        "\n",
        "filter_codes = [str(x) for x in filter_codes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_condition = \"(Listing==1)&((ScaleCategory=='TOPIX Core30')|(ScaleCategory=='TOPIX Large70')|(ScaleCategory=='TOPIX Mid400')|(ScaleCategory=='TOPIX Small 1'))\" #現行のTOPIX500\"\"\n",
        "saf = StockAcquisitionFacade(filter=filter_condition) #filtered_code_list = filter_codes)\n",
        "stock_dfs = saf.get_stock_data_dict()\n",
        "stock_dfs['list']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 価格情報の準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 目的変数（日内リターン）を算出\n",
        "stock_dfs['price']['Target'] = stock_dfs['price']['Close'] / stock_dfs['price']['Open'] - 1\n",
        "target = stock_dfs['price'][['Date', 'Code', 'Target']]\n",
        "target = target.set_index(['Date', 'Code'], drop=True).unstack(-1).droplevel(0, axis=1)\n",
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA処理の実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "end_date = datetime(2022,1,1)\n",
        "n_components = 115 # 累積寄与率がおおむね80%となる要素数\n",
        "\n",
        "\n",
        "target = target[target.index <= end_date]\n",
        "no_missing_residuals = target.dropna(axis=1).T\n",
        "\n",
        "pca = PCA(n_components = n_components).fit(no_missing_residuals)\n",
        "\n",
        "explained_ratio_df = pd.DataFrame(np.cumsum(pca.explained_variance_ratio_), \n",
        "                                  index=['PC_'+ '{:0=3}'.format(j) for j in range(0, n_components)],\n",
        "                                  columns=['ExplainedRatio'])\n",
        "explained_ratio_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_array = pca.transform(no_missing_residuals)\n",
        "\n",
        "pca_df = pd.DataFrame(pca_array, index=no_missing_residuals.index, columns=['PC_'+ '{:0=3}'.format(j) for j in range(0, n_components)])\n",
        "pca_df = pca_df[[x for x in pca_df.columns if x not in ['PC_000', 'PC_002', 'PC_003', 'PC_004']]]\n",
        "extracted_df = pca_df.sort_index(ascending=True)\n",
        "extracted_df.to_csv('pca_residue.csv')\n",
        "extracted_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### クラスタリングの関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1301,
      "metadata": {},
      "outputs": [],
      "source": [
        "# セクタークラスタリング用のクラスを準備\n",
        "clusterer = SectorClusterer(stock_dfs[\"list\"])\n",
        "\n",
        "# UMAP->HDBSCAN->距離解析を実行する関数\n",
        "def run_pipeline(df, min_cluster_sizes=None, threshold=0.03):\n",
        "    reduced = clusterer.apply_umap(df)\n",
        "    labels = clusterer.apply_hdbscan(reduced, min_cluster_sizes).rename(columns={\"Cluster\": \"HDBSCANCluster\"})\n",
        "    assigned = clusterer.determine_cluster_from_euclidean(reduced, threshold).rename(columns={\"Cluster\": \"EuclidCluster\"})\n",
        "    analysis = clusterer.analyze_cluster_distances(reduced, labels[\"HDBSCANCluster\"])\n",
        "    return assigned.join(labels).join(analysis, how=\"left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### クラスタリング(1段階目)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1302,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_codes = [\"7164\",\"8473\",\"8698\",\"8604\",\"8609\",\"8613\",\"8616\",\"8628\",\"8706\",\"8601\",\"8511\",\"8697\",\"8130\",\"7981\",\"5929\",\"5943\",\"9934\",\"5930\",\"7943\",\"6651\",\"7148\",\"5938\",\"1808\",\"8897\",\"1419\",\"1928\",\"3291\",\"4204\",\"8848\",\"1911\",\"1878\",\"1925\",\"1766\",\"8923\",\"8905\",\"8803\",\"3289\",\"8801\",\"8802\",\"8804\",\"8830\",\"3231\",\"3003\",\"8934\",\"8871\"]\n",
        "\n",
        "extracted_df = extracted_df.loc[filter_codes, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_df = run_pipeline(extracted_df)\n",
        "result_df.to_csv('cluster_hdbscan.csv')\n",
        "result_df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
